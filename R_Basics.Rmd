---
title: "R Basics Part 2 (Pre-processing)"
author: "Batch 2018 - PES University"
date: "30th Nov 2016"
output: 
  html_document:
    toc : true
    toc_float : true
    toc_depth : 5
---

# Agenda 
* Setting the Working Directory and knowing the Current working Directory
* Reading data from a csv file and Creating a Data Frame 
* Head and Tail functions
* Getting the Column names and row names
* Renaming the Columns
* Checking the data types of columns - is.* and str functions
* Converting the data into required data types - as.* function
* Subsetting the Data Frame 
* Checking for the missing values
* Imputing the missing values - Central Imputation
* Creating a new column -- Power to Weight ratio
* Numerical to Categorical - Binning
* Categorical  to Numerical - Dummifying
* Scaling the Numerical Attributes
* Creating Functions
* Using the apply family 
* Merge Functions

```{r}
rm(list = ls(all=TRUE))
```


## Present Working Directory -- getwd()
```{r}
getwd()
```
### Setting the working directory -- setwd()
```{r}
# setwd("Give the path of the datasets")
```

## Reading data from a csv file and Creating a Data Frame
   - Dataset mtcars is shared in the form of a .csv file which is needed to be read into the R environment so that any processing can be done on that data 
```{r}

### Setting the working directory -- setwd()
# setwd("/Users/indrajitv/Desktop/Lab/Datasets")

mtcars = read.csv(file = "mtcars.csv",header=TRUE,sep=",")
sum(is.na(mtcars))
class(mtcars)

mtcars = read.csv(file = "mtcars.csv",header=TRUE,sep=",",na.strings = c("NA","?"))
sum(is.na(mtcars))

```

#### Data set information (mtcars - Motor Trend Car Road Tests)
  
  The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models)..
  "The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of  multivalued discrete and continuous attributes."

* A data frame with 32 observations on 11 (numeric) variables

#### Description of the Attributes 

-	mpg	Miles/(US) gallon
-	cyl	Number of cylinders
-	disp	Displacement (cu.in.)
-	hp	Gross horsepower
-	drat	Rear axle ratio
-	wt	Weight (1000 lbs)
-	qsec	1/4 mile time
-	vs	Engine (0 = V-shaped, 1 = straight)
-	am	Transmission (0 = automatic, 1 = manual)
-	gear	Number of forward gears
-	carb	Number of carburetors

## Head and Tail functions

### Let's take a look at the top rows of the dataframe
```{r}
head(mtcars)
```

### Let's take a look at the bottom rows of the dataframe
```{r}
tail(mtcars)
```

## Structure of the R Object 

### Data types of the columns in the entire data set ()

```{r}
str(mtcars)

```

## Getting the column names and row names

### Column names
```{r}
colnames(mtcars)
```
### Row names
```{r}
rownames(mtcars)
```
## Renaming the  Rows and Columns
### Renaming the rows
```{r}

#Checking the Dimensions of the Data
dim(mtcars)

mtcars$X
rownames(mtcars) = mtcars$X
rownames(mtcars)
mtcars$X=NULL
mtcars

```

###  Renaming the  Columns
```{r}
str(mtcars)
colnames(mtcars)[6] = "weight"
```

## Checking the data types of columns - is.* and str functions
### Data type of the Column 
```{r}
# Data type of the Column checked by is.* will return in a logical vector of length 1

is.numeric(mtcars$vs)
is.character(mtcars$hp)

```

## Converting the data into required data types - as.* function
```{r}

mtcars$cyl = as.factor(mtcars$cyl)
# converting am column to factor 
mtcars$am = as.factor(mtcars$am)

```

##  Subsetting the Data Frame
### Subsetting based on column names
#### Subsetting based on a single column by name
```{r}

mtcars[,'carb']

```
#### Subsetting based on a single column by column number (also referred to as column index)
```{r}
mtcars[,11]

```

#### Subsetting using $ operator

```{r}
mtcars$carb

```

#### Subsetting two or more columns based on column name
- Observe the class of the object returned in both the cases 
```{r}
mtcars[,c('mpg','carb')]
```
#### Subsetting based on a two or more columns based on column index number

```{r}

mtcars[,c(1,11)]
class(mtcars[,c(1,11)])

```

#### Subsetting based on index row name
```{r}
rownames(mtcars)
mtcars['Duster 360',]
class(mtcars['Duster 360',])
```
#### Subsetting based on index row number
```{r}
mtcars[7,]
class(mtcars[7,])
```

#### Subsetting based on multiple index values 
```{r}
mtcars[c(6,7),]
class(mtcars[c(6,7),])
```

#### Subsetting using the subset function
```{r}
#Subsetting data
s1 <-subset(mtcars,select=c(cyl,mpg))
s1

s2 <-subset(mtcars,select=-c(cyl,mpg))
s2
```

#### Subsetting based on multiple index values and column names
```{r}
mtcars[c('Duster 360','Valiant'),c('mpg','hp')]
class(mtcars[c('Duster 360','Valiant'),c('mpg','hp')])
```


#### Subsetting based on multiple index values and column names

```{r}
mtcars[c(6,7),c(1,2)]
class(mtcars[c(6,7),c(1,2)])
```

## Checking for the missing values
### Checking by using the for loop and is.na fuction

```{r}
colsum=c()
for (i in colnames(mtcars))
{
  sum = 0
  for (j in mtcars[,i])
  {
    if(is.na(j)==TRUE)
    {
      sum = sum+1
    }else
    {
      sum = sum
    }
  }
  colsum[i] = sum
}

colsum
```
### Checking by using the colSums
```{r}
colSums(is.na(mtcars))
```
### Getting the Sum of the total NA values in the Dataset
```{r}
sum(is.na(mtcars))
```

### Dropping the records with missing values

* You can remove the na values from the datset entirely by using the na.omit() function

```{r}

# Summary Statistics
summary(mtcars)

mtcars_new <- mtcars
dim(mtcars_new)
sum(is.na(mtcars_new))

mtcars_omit <- na.omit(mtcars_new)
dim(mtcars_omit)
sum(is.na(mtcars_omit))

```

## Imputing the missing values - Central Imputation
```{r}
# install.packages("DMwR")
library(DMwR)
head(mtcars,15)
summary(mtcars)
mtcars_imputed  = centralImputation(mtcars)
colSums(is.na(mtcars_imputed))
head(mtcars_imputed,15)

```

## Creating a new feature power to weight ratio

```{r}
mtcars_imputed$pwr <-mtcars_imputed$hp/mtcars_imputed$weight 
head(mtcars_imputed)
```

## Numerical to Categorical - Binning

```{r}
# infotheo - Information Theory package
# install.packages("infotheo"")

library(infotheo)

x <- c(5,6,7,8,8,9,10,11,11,20,21,22)

length(x)

x0 <- discretize(x, disc = "equalfreq", nbins = 4)

table(x0)

x1 <- discretize(x, disc = "equalwidth", nbins = 4)

table(x1)

```

### manual binning
```{r}
mtcars_imputed$hp
# After looking the numbers we can get the idea of how to bin them 
bins = cut(mtcars_imputed$hp,breaks = seq(0,350,50),include.lowest = T,right = T)
bins
# Count the number of rows that comes under a particular bin
table(bins)

```

### use the *discretize* function from infotheo package
```{r}
library(infotheo)
(nbins = floor(sqrt(NROW(mtcars_imputed $hp))))
eq_wid_bin=discretize(mtcars_imputed $hp,disc = "equalwidth",nbins)
table(eq_wid_bin)

```

```{r}

eq_freq_bin<-discretize(mtcars_imputed $hp,disc = "equalfreq",nbins)
table(eq_freq_bin)

```

```{r}
str(mtcars_imputed)
```

## Categorical to Numerical 

```{r}
library(dummies)
mtcars_imputed$vs
dummy(mtcars_imputed$vs)

```

## Scaling the Numerical Attribute

```{r}
library(vegan)

# Using Range method

mtcars_imputed_range <- decostand(x =mtcars_imputed[,c('mpg','disp','drat','weight','qsec','gear','carb')],method ="range",MARGIN = 2)

str(mtcars_imputed_range)

range(mtcars_imputed_range$mpg)

head(mtcars_imputed_range)

```

```{r}

# Using Z score method

mtcars_imputed_standardized <- decostand(x =mtcars_imputed[,c('mpg','disp','drat','weight','qsec','gear','carb')],method ="standardize",MARGIN = 2)
range(mtcars_imputed_standardized$mpg)
head(mtcars_imputed_standardized)

```


## Family of *apply* functions 
- We can do some very complex operations with using these handy functions from the *apply* family of functions
- apply functions take a list/vector or dataframe as input, apply a function on the input and produce the output, let us look a some of the apply functions and how to use them.

#### *apply*
- apply takes input
  - 1. Dataframe
  - 2. An argument which specfies if we want to apply the funtions row wise or column wise and
  - 3. The function we want to apply

- syntax :  apply(X,1 (or 2) ,FUN)
  - 1 for rows
  - 2 for columns

#### apply the mean and max function on columns
```{r}
apply_mtcars=apply(mtcars_imputed_range[,-c(1)],2,max)
apply_mtcars
class(apply(mtcars_imputed_range[,-c(1)],2,max))
apply(mtcars_imputed_range,2,mean)

```

#### *lapply*
- lapply takes a list as an input, and returns a list as the output.

- syntax :  lapply(X,FUN)



#### mean function on a column in the dataframe  mtcars
```{r}
lapply(mtcars['mpg'],mean)
df_mean = lapply(mtcars_imputed_range,mean)
class(df_mean)

# Assignment:
# Create an empty list and store the output of lapply result on mtcars dataset
empty_list=lapply(mtcars_imputed_range,mean)
empty_list

```

##### Assignment
```{r}

# Create a matrix values ranging from 1 to 100 (values should be assigned row-wise) and apply
# Q-1 : (a) get the sum of the values in every row
#       (b) get the product of the values in every row
# Q-2 : (a) get the sum of the values in every column
#       (b) get the product of the values in every column

# Create the matrix
m<-matrix(c(seq(from=1,to=100,by=1)),nrow=10,ncol=10,byrow = TRUE)
View(m)

# Q-1
# (a)
  apply(X = m, MARGIN = 1,FUN = sum)
# (b)
  apply(X = m, MARGIN = 1,FUN = prod)
  
# Q-2
# (a)
  apply(X = m, MARGIN = 2,FUN = sum)
# (b)
  apply(X = m, MARGIN = 2,FUN = prod)

```


#### *sapply*
- sapply takes a list as an input, and returns a vector as output.

- syntax :  sapply(X,FUN)

#### min and max function on a column in the dataframe  mtcars
```{r}
sapply(mtcars_imputed_range['mpg'],max)
class(sapply(mtcars['mpg'],max))

sapply_vec= sapply(mtcars_imputed_range,min)
sapply_vec

```

#### *tapply*
- tapply splits the array based on specified data, usually factor levels and then applies the function to it.

- syntax :  tapply(X,Y,FUN)
- tapply splits X based on levels in Y


#### mean function on a column in the dataframe mtcars
```{r}
str(mtcars_imputed)
```

```{r}
tapply(mtcars_imputed$weight, mtcars_imputed$am, mean)
tapply(mtcars_imputed$weight, mtcars_imputed$cyl, median)
tapply(mtcars_imputed$weight, mtcars_imputed$vs, range)
class(tapply(mtcars_imputed$weight, mtcars_imputed$am, mean))

tapply(mtcars_imputed$weight, mtcars_imputed$drat, mean)
```

#### Find the max hp of cars based on number of cylinders

```{r}
tapply(mtcars$hp,mtcars$cyl,max)
```

## Merge Functions

### Reading Data from two files and merging the data 
```{r}

library(openxlsx)

setwd("/Users/indrajitv/Desktop/Lab/Datasets")

cust_bank_details_sample_1 = read.xlsx('Customer_sample_1.xlsx',sheet  = "Customer_Bank Details_MV")
cust_demographics_sample_2 = read.xlsx('Customer_sample_2.xlsx',sheet = "Customer_Demographics_MV_DOB")

```

```{r}

head(cust_bank_details_sample_1)

```

```{r}

head(cust_demographics_sample_2)

```

```{r}

library(base)

# Inner Join
IJ_merged_df_sample <- merge(x = cust_bank_details_sample_1, y = cust_demographics_sample_2, 
                             by.x = "ID", by.y = "Customer.ID")
View(IJ_merged_df_sample)

#Left Outer Join
LoJ_merged_df_sample = merge(x = cust_bank_details_sample_1, y = cust_demographics_sample_2,  
                             by.x = "ID", by.y = "Customer.ID", all.x = TRUE)
View(LoJ_merged_df_sample)
  
#Right Outer Join
RoJ_merged_df_sample <- merge(x = cust_bank_details_sample_1, y = cust_demographics_sample_2,  
                              by.x = "ID", by.y = "Customer.ID", all.y = TRUE)
View(RoJ_merged_df_sample)

#Full Outer Join
FoJ_merged_df_sample <- merge(x = cust_bank_details_sample_1, y = cust_demographics_sample_2,  
                              by.x = "ID", by.y = "Customer.ID", all = TRUE)
View(FoJ_merged_df_sample)

```

## Practice

```{r}

setwd("/Users/indrajitv/Desktop/Lab/Datasets")

cust_bank_details = read.xlsx("Customer_Bank_Details_MV.xlsx",sheet  = "Customer_Bank Details_MV")
cust_demographics = read.xlsx("Customer_Demographics_MV_DOB.xlsx",sheet = "Customer_Demographics_MV_DOB")

```

```{r}
head(cust_bank_details)
```

```{r}
head(cust_demographics)
```

#### Combining/Merging/Joining data from multiple files.

```{r}

library(base)

# Inner Join
IJ_merged_df <- merge(x = cust_bank_details,y = cust_demographics, by.x = "ID", by.y = "Customer.ID")

#Left Outer Join
LoJ_merged_df = merge(x = cust_bank_details, y = cust_demographics,  by.x = "ID", by.y = "Customer.ID", all.x = TRUE)
  
#Right Outer Join
RoJ_merged_df <- merge(x = cust_bank_details, y = cust_demographics,  by.x = "ID", by.y = "Customer.ID", all.y = TRUE)

#Full Outer Join
FoJ_merged_df <- merge(x = cust_bank_details, y = cust_demographics,  by.x = "ID", by.y = "Customer.ID", all = TRUE)

View(IJ_merged_df)
head(IJ_merged_df)

```
## Few more functions

```{r}
# While creating a vector, if we want to create elements randomly, we use sample function
A<-sample(x = 1:10, size = 20, replace = T)
A

# Function to get the size of a vector-length
length(A)

# In some cases, as in sample with replace=T, the elements may repeat, To get the unique elements
unique(A)

# To get how many unique elements are in A
length(unique(A))

# We have a dataframe DF and we want to know the dimensions of it
# dim(DF)
dim(mtcars)

# To get the number of rows and number of columns of DF-nrow and ncol respectively
nrow(mtcars)
ncol(mtcars)

#################### R environment ####################

ls()
# rm(list=c("A","B"))

ls()
rm(list=ls())

#################### How to check the help ####################

# help(mean) # or ?mean

#################### Package Installation ####################

# install.packages(c("", ""))
# installed.packages()

```

```{r}

########################## Read and write a file in R ###########################


# To read and write a file
# csv

setwd("/Users/indrajitv/Desktop/Lab/Datasets")

Data<-read.csv("SampleData.csv",header=T,sep=",")
Data

# txt and tsv
Data<-read.table("SampleData.txt",header=T,sep="\t") 
Data
write.table(Data,"Data2.txt",row.names=F,sep="\t") # check without row.names argument
write.table(Data,"Data3.tsv",row.names=F) # check without row.names argument

A<-read.table("Data3.tsv",header=T)
A

data("iris")

iris_df=iris
head(iris_df,10)
write.csv(iris_df,file="iris_df.csv",row.names = FALSE)

```

## Few Additional Useful Functionalities

### Fast Read Function
```{r}

# library(data.table)

# Reading the Large Dataset using the Normal Read Functionality
# system.time(ip_data1 <- read.csv("/home/indrajitv/Desktop/Lab/Datasets/large_dataset.csv"))

# Reading the Large Dataset using the Fast-Read Functionality in 'data.table' Library
# system.time(ip_data2 <- data.table::fread("/home/indrajitv/Desktop/Lab/Datasets/large_dataset.csv"))

```



## CREATING YOUR OWN PACKAGE !!!

